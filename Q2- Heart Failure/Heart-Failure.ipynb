{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEART FAILURE EARLY DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT ALL LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vecstack in f:\\datascience\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in f:\\datascience\\lib\\site-packages (from vecstack) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in f:\\datascience\\lib\\site-packages (from vecstack) (0.24.1)\n",
      "Requirement already satisfied: scipy in f:\\datascience\\lib\\site-packages (from vecstack) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in f:\\datascience\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in f:\\datascience\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#!pip install imbalanced-learn\n",
    "#!pip install mlxtend\n",
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install vecstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIND ANY MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         0\n",
       "anaemia                     0\n",
       "creatinine_phosphokinase    0\n",
       "diabetes                    0\n",
       "ejection_fraction           0\n",
       "high_blood_pressure         0\n",
       "platelets                   0\n",
       "serum_creatinine            0\n",
       "serum_sodium                0\n",
       "sex                         0\n",
       "smoking                     0\n",
       "time                        0\n",
       "DEATH_EVENT                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFORMATION ON DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBSERVATIONS PRESENT IN TARGET VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    203\n",
       "1     96\n",
       "Name: DEATH_EVENT, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DEATH_EVENT'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPERATE INDEPENDENT AND DEPENDENT (TARGET) VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('DEATH_EVENT',axis=1)\n",
    "y=df['DEATH_EVENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCALE THE INDEPENDENT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.19294523e+00, -8.71104775e-01,  1.65728387e-04, ...,\n",
       "         7.35688190e-01, -6.87681906e-01, -1.62950241e+00],\n",
       "       [-4.91279276e-01, -8.71104775e-01,  7.51463953e+00, ...,\n",
       "         7.35688190e-01, -6.87681906e-01, -1.60369074e+00],\n",
       "       [ 3.50832977e-01, -8.71104775e-01, -4.49938761e-01, ...,\n",
       "         7.35688190e-01,  1.45416070e+00, -1.59078490e+00],\n",
       "       ...,\n",
       "       [-1.33339153e+00, -8.71104775e-01,  1.52597865e+00, ...,\n",
       "        -1.35927151e+00, -6.87681906e-01,  1.90669738e+00],\n",
       "       [-1.33339153e+00, -8.71104775e-01,  1.89039811e+00, ...,\n",
       "         7.35688190e-01,  1.45416070e+00,  1.93250906e+00],\n",
       "       [-9.12335403e-01, -8.71104775e-01, -3.98321274e-01, ...,\n",
       "         7.35688190e-01,  1.45416070e+00,  1.99703825e+00]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT DATA INTO TRAINING AND TEST DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE XGBCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO OVERSAMPLING FOR THE IMBALANCED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 83\n",
      "Before OverSampling, counts of label '0': 156 \n",
      "\n",
      "After OverSampling, the shape of train_X: (312, 12)\n",
      "After OverSampling, the shape of train_y: (312,) \n",
      "\n",
      "After OverSampling, counts of label '1': 156\n",
      "After OverSampling, counts of label '0': 156\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
    "  \n",
    "# import SMOTE module from imblearn library \n",
    "# pip install imblearn (if you don't have imblearn in your system) \n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel()) \n",
    "  \n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE RANDOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE RANDOM FOREST PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'n_estimators': range(100,2000),\n",
    "               'max_depth': range(1,100),\n",
    "               'min_samples_split': range(1,10),\n",
    "               'min_samples_leaf': range(1,10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN, TEST AND EVALUATE THE COST EFFECTIVE RANDOM FOREST ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataScience\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.8033196  0.81277473        nan 0.8095696  0.8077381  0.81369048\n",
      " 0.8132326  0.81277473 0.8095696  0.81369048 0.8132326  0.81277473\n",
      " 0.81643773 0.79981685 0.81369048        nan 0.81918498 0.81277473\n",
      " 0.8077381  0.79874084 0.81247711 0.81872711 0.80927198 0.81643773\n",
      " 0.81277473 0.8095696  0.81568223 0.82239011 0.81369048 0.80927198\n",
      " 0.80927198        nan 0.81918498 0.80286172        nan 0.81872711\n",
      " 0.80606685 0.81918498 0.81964286 0.81552198        nan 0.8014881\n",
      " 0.8033196  0.81048535 0.81597985 0.8014881         nan 0.80728022\n",
      " 0.80744048 0.77554945]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(1, 100),\n",
       "                                        'min_samples_leaf': range(1, 10),\n",
       "                                        'min_samples_split': range(1, 10),\n",
       "                                        'n_estimators': range(100, 2000)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_mse_rft = RandomizedSearchCV(estimator=clf,param_distributions=random_grid,n_iter=50, scoring='balanced_accuracy', cv=4, verbose=1,n_jobs=-1)\n",
    "randomized_mse_rft.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = randomized_mse_rft.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: [0.93333333]\n"
     ]
    }
   ],
   "source": [
    "print('Final prediction score: [%.8f]' % accuracy_score(y_test, rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "t=confusion_matrix(y_test, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(60, 12)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "sns.heatmap(t, cmap=\"Greys\", annot=True, annot_kws={\"size\":15}, fmt=\"g\")\n",
    "ax.set_ylim(2, 0)\n",
    "plt.show()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9090909090909091\n",
      "Recall: 0.7692307692307693\n",
      "F1: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, rf)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, rf)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, rf)))\n",
    "print(\"F1: {}\".format(f1_score(y_test, rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE THE PARAMETERS OF XGBCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_param_grid_final = {\n",
    "  'colsample_bytree': range(0, 1),\n",
    "    'n_estimators': range(50,100),\n",
    "    'max_depth': range(1, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN, TEST, AND EVALUATE THE XGBCLASSIFIER ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid_mse = GridSearchCV(estimator=model,param_grid=gbm_param_grid_final, scoring='balanced_accuracy', cv=4, verbose=1,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "[12:34:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1, param_grid={'n_estimators': range(50, 100)},\n",
       "             scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_mse.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST XGBCLASSIFIER ESTIMATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier(base_score=None, booster=None,\n",
    "                                     colsample_bylevel=None,\n",
    "                                     colsample_bynode=None,\n",
    "                                     colsample_bytree=None, gamma=None,\n",
    "                                     gpu_id=None, importance_type='gain',\n",
    "                                     interaction_constraints=None,\n",
    "                                     learning_rate=None, max_delta_step=None,\n",
    "                                     max_depth=None, min_child_weight=None,\n",
    "                                     missing=None, monotone_constraints=None,\n",
    "                                     n_estimators=100, n_jobs=None,\n",
    "                                     num_parallel_tree=None, random_state=None,\n",
    "                                     reg_alpha=None, reg_lambda=None,\n",
    "                                     scale_pos_weight=None, subsample=None,\n",
    "                                     tree_method=None, validate_parameters=None,\n",
    "                                     verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8653846153846153"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_mse.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN, TEST, AND EVALUATE NON-COST SENSITIVE RANDOM FOREST ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_mse_rf = RandomizedSearchCV(estimator=clf,param_distributions=random_grid,n_iter=50, scoring='balanced_accuracy', cv=4, verbose=1,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataScience\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.85576923        nan 0.86217949 0.8525641  0.86217949 0.86217949\n",
      " 0.86538462 0.85897436 0.86217949 0.86217949        nan 0.8525641\n",
      " 0.86217949 0.86217949        nan 0.8525641  0.86217949 0.85897436\n",
      " 0.85897436 0.86538462 0.86858974        nan 0.8525641  0.86217949\n",
      " 0.86217949 0.8525641  0.86217949 0.85897436 0.85897436 0.85897436\n",
      " 0.8525641  0.86217949 0.8525641  0.85576923 0.86217949 0.86538462\n",
      "        nan 0.86217949 0.84615385        nan 0.86538462 0.86538462\n",
      " 0.83333333 0.86217949 0.85576923 0.85897436 0.84935897        nan\n",
      " 0.86858974 0.86217949]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(1, 100),\n",
       "                                        'min_samples_leaf': range(1, 10),\n",
       "                                        'min_samples_split': range(1, 10),\n",
       "                                        'n_estimators': range(100, 2000)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_mse_rf.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8685897435897436"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_mse_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACK THE MODELS OF NON-COST-SENSITIVE RANDOM FOREST AND XGBCLASSIFIER ALGORITHMS WITH MLXTEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:57:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(classifiers=[RandomForestClassifier(max_depth=69,\n",
       "                                                       min_samples_leaf=5,\n",
       "                                                       min_samples_split=6,\n",
       "                                                       n_estimators=1939),\n",
       "                                XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                              colsample_bylevel=1,\n",
       "                                              colsample_bynode=1,\n",
       "                                              colsample_bytree=1, gamma=0,\n",
       "                                              gpu_id=-1, importance_type='gain',\n",
       "                                              interaction_constraints='',\n",
       "                                              learning_rate=0.300000012,\n",
       "                                              max_delta_step=0, max_depth=6,\n",
       "                                              min_child_weight=1, missing=nan,\n",
       "                                              monotone_constraints='()',\n",
       "                                              n_estimators=50, n_jobs=16,\n",
       "                                              num_parallel_tree=1,\n",
       "                                              random_state=0, reg_alpha=0,\n",
       "                                              reg_lambda=1, scale_pos_weight=1,\n",
       "                                              subsample=1, tree_method='exact',\n",
       "                                              validate_parameters=1,\n",
       "                                              verbosity=None)],\n",
       "                   meta_classifier=RandomForestClassifier(max_depth=69,\n",
       "                                                          min_samples_leaf=5,\n",
       "                                                          min_samples_split=6,\n",
       "                                                          n_estimators=1939))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_stack=StackingClassifier(classifiers=[randomized_mse_rf.best_estimator_,Grid_mse.best_estimator_],meta_classifier=randomized_mse_rf.best_estimator_,use_features_in_secondary=False)\n",
    "clf_stack.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERFITTING CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_train, clf_stack.predict(X_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERFITTING DETECTED MOVE ONTO NEXT TRAINING METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, clf_stack.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE ADABOOSTCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc =AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE ADABOOST PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_param_grid_final = {\n",
    "    'n_estimators': range(50,100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN, TEST, AND EVALUATE THE ADABOOST ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid_mse_abc = GridSearchCV(estimator=abc,param_grid=abc_param_grid_final, scoring='balanced_accuracy', cv=4, verbose=1,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={'n_estimators': range(50, 100)},\n",
       "             scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_mse_abc.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=52)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_mse_abc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8237179487179488"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_mse_abc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE BEST ADABOOST ESTIMATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC=AdaBoostClassifier(n_estimators=52,base_estimator=randomized_mse_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACK XGBCLASSIFIER, RANDOM FOREST, ADABOOST CLASSIFIER WITH VECSTACK METHOD AND TRAIN, TEST, AND EVALUATE THIS METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [AdaBoostClassifier]\n",
      "    fold  0:  [0.88461538]\n",
      "    fold  1:  [0.88461538]\n",
      "    fold  2:  [0.88461538]\n",
      "    fold  3:  [0.84615385]\n",
      "    ----\n",
      "    MEAN:     [0.87500000] + [0.01665433]\n",
      "    FULL:     [0.87500000]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.88461538]\n",
      "    fold  1:  [0.88461538]\n",
      "    fold  2:  [0.88461538]\n",
      "    fold  3:  [0.79487179]\n",
      "    ----\n",
      "    MEAN:     [0.86217949] + [0.03886011]\n",
      "    FULL:     [0.86217949]\n",
      "\n",
      "model  2:     [XGBClassifier]\n",
      "[21:40:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    fold  0:  [0.85897436]\n",
      "[21:40:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    fold  1:  [0.88461538]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[21:40:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    fold  2:  [0.85897436]\n",
      "[21:40:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    fold  3:  [0.87179487]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ----\n",
      "    MEAN:     [0.86858974] + [0.01063021]\n",
      "    FULL:     [0.86858974]\n",
      "\n",
      "Final prediction score: [0.90000000]\n"
     ]
    }
   ],
   "source": [
    "stacked_models = [ABC,randomized_mse_rf.best_estimator_,xgb]\n",
    "# Stack the models: stack_train, stack_test\n",
    "stack_train, stack_test = stacking(stacked_models, X_train_res, y_train_res, X_test, regression=False, mode='oof_pred_bag',\n",
    "needs_proba=False, metric=accuracy_score, n_folds=4, stratified=True, shuffle=True, random_state=0, verbose=2)\n",
    "# Initialize and fit 2nd level model\n",
    "final_model = ABC\n",
    "final_model_fit = final_model.fit(stack_train, y_train_res)\n",
    "# Predict: stacked_pred\n",
    "stacked_pred = final_model.predict(stack_test)\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % accuracy_score(y_test, stacked_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=confusion_matrix(y_test, stacked_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(60, 12)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "sns.heatmap(o, cmap=\"Greys\", annot=True, annot_kws={\"size\":15}, fmt=\"g\")\n",
    "ax.set_ylim(2, 0)\n",
    "plt.show()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Precision: 0.7058823529411765\n",
      "Recall: 0.9230769230769231\n",
      "F1: 0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, stacked_pred)))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, stacked_pred)))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, stacked_pred)))\n",
    "print(\"F1: {}\".format(f1_score(y_test, stacked_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNDERSAMPLING TO ADDRESS THE IMBALANCE IN THE DATASET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before UnderSampling, counts of label '1': 83\n",
      "Before UnderSampling, counts of label '0': 156 \n",
      "\n",
      "After UnderSampling, the shape of train_X: (166, 12)\n",
      "After UnderSampling, the shape of train_y: (166,) \n",
      "\n",
      "After UnderSampling, counts of label '1': 83\n",
      "After UnderSampling, counts of label '0': 83\n"
     ]
    }
   ],
   "source": [
    "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
    "  \n",
    "# import SMOTE module from imblearn library \n",
    "# pip install imblearn (if you don't have imblearn in your system) \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "under = RandomUnderSampler()\n",
    "X_train_und, y_train_und = under.fit_resample(X_train, y_train.ravel()) \n",
    "  \n",
    "print('After UnderSampling, the shape of train_X: {}'.format(X_train_und.shape)) \n",
    "print('After UnderSampling, the shape of train_y: {} \\n'.format(y_train_und.shape)) \n",
    "  \n",
    "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_und == 1))) \n",
    "print(\"After UnderSampling, counts of label '0': {}\".format(sum(y_train_und == 0))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN, TEST AND EVALUATE THE UNDERSAMPLING METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "[13:54:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1, param_grid={'n_estimators': range(50, 100)},\n",
       "             scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_mse.fit(X_train_und,y_train_und)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8565476190476191"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_mse.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataScience\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.85654762 0.86845238 0.86815476 0.85654762 0.84464286 0.87380952\n",
      " 0.87410714 0.88035714 0.85654762 0.87380952 0.85059524 0.85654762\n",
      " 0.87380952        nan 0.84464286 0.85625    0.86785714 0.85654762\n",
      " 0.85654762 0.85595238 0.85625           nan 0.86220238 0.86785714\n",
      " 0.85059524        nan 0.85059524 0.85654762 0.85654762 0.86815476\n",
      " 0.84464286 0.87440476        nan 0.85654762 0.88035714 0.8625\n",
      "        nan 0.8625     0.87380952 0.86220238 0.86845238 0.85029762\n",
      " 0.85059524 0.84404762 0.85654762        nan 0.88035714 0.86815476\n",
      " 0.86815476 0.86220238]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(1, 100),\n",
       "                                        'min_samples_leaf': range(1, 10),\n",
       "                                        'min_samples_split': range(1, 10),\n",
       "                                        'n_estimators': range(100, 2000)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_mse_rfu = RandomizedSearchCV(estimator=clf,param_distributions=random_grid,n_iter=50, scoring='balanced_accuracy', cv=4, verbose=1,n_jobs=-1)\n",
    "randomized_mse_rfu.fit(X_train_und,y_train_und)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803571428571428"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_mse_rfu.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={'n_estimators': range(50, 100)},\n",
       "             scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_mse_abc.fit(X_train_und,y_train_und)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831547619047619"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_mse_abc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC_under=AdaBoostClassifier(n_estimators=56,base_estimator=randomized_mse_rfu.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [AdaBoostClassifier]\n",
      "    fold  0:  [0.80952381]\n",
      "    fold  1:  [0.88095238]\n",
      "    fold  2:  [0.85365854]\n",
      "    fold  3:  [0.87804878]\n",
      "    ----\n",
      "    MEAN:     [0.85554588] + [0.02860710]\n",
      "    FULL:     [0.85542169]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.80952381]\n",
      "    fold  1:  [0.88095238]\n",
      "    fold  2:  [0.85365854]\n",
      "    fold  3:  [0.87804878]\n",
      "    ----\n",
      "    MEAN:     [0.85554588] + [0.02860710]\n",
      "    FULL:     [0.85542169]\n",
      "\n",
      "model  2:     [XGBClassifier]\n",
      "[14:03:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    fold  0:  [0.83333333]\n",
      "[14:03:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    fold  1:  [0.88095238]\n",
      "[14:03:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    fold  2:  [0.85365854]\n",
      "[14:03:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    fold  3:  [0.87804878]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\DataScience\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ----\n",
      "    MEAN:     [0.86149826] + [0.01941074]\n",
      "    FULL:     [0.86144578]\n",
      "\n",
      "Final prediction score: [0.83333333]\n"
     ]
    }
   ],
   "source": [
    "stacked_models9 = [ABC_under,randomized_mse_rfu.best_estimator_,Grid_mse.best_estimator_]\n",
    "# Stack the models: stack_train, stack_test\n",
    "stack_train9, stack_test9 = stacking(stacked_models9, X_train_und, y_train_und, X_test, regression=False, mode='oof_pred_bag',\n",
    "needs_proba=False, metric=accuracy_score, n_folds=4, stratified=True, shuffle=True, random_state=0, verbose=2)\n",
    "# Initialize and fit 2nd level model\n",
    "final_model9 = randomized_mse_rfu.best_estimator_\n",
    "final_model_fit9 = final_model9.fit(stack_train9, y_train_und)\n",
    "# Predict: stacked_pred\n",
    "stacked_pred9 = final_model9.predict(stack_test9)\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % accuracy_score(y_test, stacked_pred9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
